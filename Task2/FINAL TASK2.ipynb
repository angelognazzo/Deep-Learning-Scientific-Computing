{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils\n",
    "import torch.utils.data\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "NEURAL NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_dimension,\n",
    "                 output_dimension,\n",
    "                 n_hidden_layers,\n",
    "                 neurons,\n",
    "                 regularization_param,\n",
    "                 regularization_exp,\n",
    "                 retrain_seed,\n",
    "                 activation_name):\n",
    "\n",
    "        super(NeuralNet, self).__init__()\n",
    "        # Number of input dimensions n\n",
    "        self.input_dimension = input_dimension\n",
    "        # Number of output dimensions m\n",
    "        self.output_dimension = output_dimension\n",
    "        # Number of neurons per layer\n",
    "        self.neurons = neurons\n",
    "        # Number of hidden layers\n",
    "        self.n_hidden_layers = n_hidden_layers\n",
    "        # Activation function\n",
    "        self.activation_name = activation_name\n",
    "        self.activation = self.get_activation(activation_name)\n",
    "        # Regularization parameter\n",
    "        self.regularization_param = regularization_param\n",
    "        # Regularization exponent\n",
    "        self.regularization_exp = regularization_exp\n",
    "        # Random seed for weight initialization\n",
    "        self.retrain_seed = retrain_seed\n",
    "\n",
    "        if self.n_hidden_layers != 0:\n",
    "            self.input_layer = nn.Linear(self.input_dimension, self.neurons)\n",
    "            self.hidden_layers = nn.ModuleList([nn.Linear(self.neurons, self.neurons) for _ in range(n_hidden_layers - 1)])\n",
    "            self.output_layer = nn.Linear(self.neurons, self.output_dimension)\n",
    "\n",
    "        else:\n",
    "            print(\"Simple linear regression\")\n",
    "            self.linear_regression_layer = nn.Linear(self.input_dimension, self.output_dimension)\n",
    "\n",
    "        self.init_xavier()\n",
    "\n",
    "    def init_xavier(self):\n",
    "        torch.manual_seed(self.retrain_seed)\n",
    "\n",
    "        def init_weights(m):\n",
    "            if type(m) == nn.Linear and m.weight.requires_grad and m.bias.requires_grad:\n",
    "                if self.activation_name in ['tanh', 'relu']:\n",
    "                    gain = nn.init.calculate_gain(self.activation_name)\n",
    "                else:\n",
    "                    gain = 1\n",
    "                torch.nn.init.xavier_uniform_(m.weight, gain=gain)\n",
    "                m.bias.data.fill_(0)\n",
    "\n",
    "        self.apply(init_weights)\n",
    "\n",
    "    def regularization(self):\n",
    "        reg_loss = 0\n",
    "        for name, param in self.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                reg_loss = reg_loss + torch.norm(param, self.regularization_exp)\n",
    "        return reg_loss\n",
    "\n",
    "    def get_activation(self, activation_name):\n",
    "        if activation_name in ['tanh']:\n",
    "            return nn.Tanh()\n",
    "        elif activation_name in ['relu']:\n",
    "            return nn.ReLU(inplace=True)\n",
    "        elif activation_name in ['lrelu']:\n",
    "            return nn.LeakyReLU(inplace=True)\n",
    "        elif activation_name in ['sigmoid']:\n",
    "            return nn.Sigmoid()\n",
    "        elif activation_name in ['softplus']:\n",
    "            return nn.Softplus(beta=4)\n",
    "        elif activation_name in ['celu']:\n",
    "            return nn.CELU()\n",
    "        else:\n",
    "            raise ValueError('Unknown activation function')\n",
    "\n",
    "    def forward(self, x):\n",
    "        # The forward function performs the set of affine and non-linear transformations defining the network\n",
    "        # (see equation above)\n",
    "        if self.n_hidden_layers != 0:\n",
    "            x = self.activation(self.input_layer(x))\n",
    "            for k, l in enumerate(self.hidden_layers):\n",
    "                x = self.activation(l(x))\n",
    "            return self.output_layer(x)\n",
    "        else:\n",
    "            return self.linear_regression_layer(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def run_single_configuration(conf_dict, x_, y_):\n",
    "    # Set random seed for reproducibility\n",
    "    torch.manual_seed(42)\n",
    "    np.random.seed(42)\n",
    "\n",
    "    print(conf_dict)\n",
    "\n",
    "    # Get the configuration to test\n",
    "    opt_type = conf_dict[\"optimizer\"]\n",
    "    n_epochs = conf_dict[\"epochs\"]\n",
    "    n_hidden_layers = conf_dict[\"hidden_layers\"]\n",
    "    neurons = conf_dict[\"neurons\"]\n",
    "    regularization_param = conf_dict[\"regularization_param\"]\n",
    "    regularization_exp = conf_dict[\"regularization_exp\"]\n",
    "    retrain_seed = conf_dict[\"init_weight_seed\"]\n",
    "    batch_size = conf_dict[\"batch_size\"]\n",
    "    activation = conf_dict[\"activation\"]\n",
    "\n",
    "    validation_size = int(20 * x_.shape[0] / 100)\n",
    "    training_size = x_.shape[0] - validation_size\n",
    "    x_train = x_[:training_size, :]\n",
    "    y_train = y_[:training_size, :]\n",
    "\n",
    "    x_val = x_[training_size:, :]\n",
    "    y_val = y_[training_size:, :]\n",
    "\n",
    "    training_set = DataLoader(torch.utils.data.TensorDataset(x_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    my_network = NeuralNet(input_dimension=x_.shape[1],\n",
    "                           output_dimension=y_.shape[1],\n",
    "                           n_hidden_layers=n_hidden_layers,\n",
    "                           neurons=neurons,\n",
    "                           regularization_param=regularization_param,\n",
    "                           regularization_exp=regularization_exp,\n",
    "                           retrain_seed=retrain_seed,\n",
    "                           activation_name=activation)\n",
    "\n",
    "    if opt_type == \"ADAM\":\n",
    "        optimizer_ = optim.Adam(my_network.parameters(), lr=0.001)\n",
    "    elif opt_type == \"LBFGS\":\n",
    "        optimizer_ = optim.LBFGS(my_network.parameters(), lr=0.1, max_iter=1, max_eval=50000, tolerance_change=1.0 * np.finfo(float).eps)\n",
    "    else:\n",
    "        raise ValueError(\"Optimizer not recognized\")\n",
    "\n",
    "    history = fit(my_network, training_set, x_val, y_val, n_epochs, optimizer_, p=2, verbose=False)\n",
    "\n",
    "    y_val = y_val.reshape(-1, )\n",
    "    y_train = y_train.reshape(-1, )\n",
    "\n",
    "    #y_test_pred = my_network(x_test).reshape(-1, )\n",
    "    y_val_pred = my_network(x_val).reshape(-1, )\n",
    "    y_train_pred = my_network(x_train).reshape(-1, )\n",
    "\n",
    "    # Compute the relative training error\n",
    "    relative_error_train = torch.mean((y_train_pred - y_train) ** 2) / torch.mean(y_train ** 2)\n",
    "    print(\"Relative Training Error: \", relative_error_train.detach().numpy() ** 0.5 * 100, \"%\")\n",
    "\n",
    "    # Compute the relative validation error\n",
    "    relative_error_val = torch.mean((y_val_pred - y_val) ** 2) / torch.mean(y_val ** 2)\n",
    "    print(\"Relative Validation Error: \", relative_error_val.detach().numpy() ** 0.5 * 100, \"%\")\n",
    "\n",
    "    return relative_error_train.item(), relative_error_val.item(), my_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def fit(model, training_set, x_validation_, y_validation_, num_epochs, optimizer, p, verbose=True):\n",
    "    history = [[], []]\n",
    "    regularization_param = model.regularization_param\n",
    "\n",
    "    # Loop over epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        if verbose: print(\"################################ \", epoch, \" ################################\")\n",
    "\n",
    "        running_loss = list([0])\n",
    "\n",
    "        # Loop over batches\n",
    "        for j, (x_train_, u_train_) in enumerate(training_set):\n",
    "            def closure():\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                # forward + backward + optimize\n",
    "                u_pred_ = model(x_train_)\n",
    "                loss_u = torch.mean((u_pred_.reshape(-1, ) - u_train_.reshape(-1, )) ** p)\n",
    "                loss_reg = model.regularization()\n",
    "                loss = loss_u + regularization_param * loss_reg\n",
    "                loss.backward()\n",
    "                # Compute average training loss over batches for the current epoch\n",
    "                running_loss[0] += loss.item() / len(training_set)\n",
    "                return loss\n",
    "\n",
    "            optimizer.step(closure=closure)\n",
    "\n",
    "        y_validation_pred_ = model(x_validation_)\n",
    "        validation_loss = torch.mean((y_validation_pred_.reshape(-1, ) - y_validation_.reshape(-1, )) ** p).item()\n",
    "        history[0].append(running_loss[0])\n",
    "        history[1].append(validation_loss)\n",
    "\n",
    "        if verbose:\n",
    "            print('Training Loss: ', np.round(running_loss[0], 8))\n",
    "            print('Validation Loss: ', np.round(validation_loss, 8))\n",
    "\n",
    "    print('Final Training Loss: ', np.round(history[0][-1], 8))\n",
    "    print('Final Validation Loss: ', np.round(history[1][-1], 8))\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "DATA AND DETAILS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "32 RANDOM ELEMENTS AS VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sampling_seed = 74\n",
    "torch.manual_seed(sampling_seed)\n",
    "\n",
    "data101 = np.loadtxt('TrainingData_101.txt', delimiter=' ')\n",
    "data401 = np.loadtxt('TrainingData_401.txt', delimiter=' ')\n",
    "data1601 = np.loadtxt('TrainingData_1601.txt', delimiter=' ')\n",
    "sobol = np.loadtxt('samples_sobol.txt', delimiter=' ')\n",
    "\n",
    "datasets_meshes=[]\n",
    "datasets_meshes.append(data101)\n",
    "datasets_meshes.append(data401)\n",
    "datasets_meshes.append(data1601)\n",
    "\n",
    "valid_index = random.sample(range(160), 32)\n",
    "training_sets = list()\n",
    "# save min a max of details to detransform the output after NN\n",
    "minima_det = list()\n",
    "maxima_det = list()\n",
    "\n",
    "data_validation = np.concatenate([sobol[valid_index,:], data1601[valid_index,8].reshape(-1,1)], 1)\n",
    "ts_detail_l = np.concatenate([np.delete(sobol, valid_index, 0), np.delete(data101, valid_index, 0)[:,8].reshape(-1,1)], 1)\n",
    "training_sets.append(ts_detail_l)\n",
    "\n",
    "# Obtain the details at different mesh resolutions\n",
    "# can try different normalizations for the two details\n",
    "for l in range(1, 3):\n",
    "    ns = datasets_meshes[l].shape[0]\n",
    "    obs_difff = datasets_meshes[l][:ns, -1] - datasets_meshes[l - 1][:ns, -1]\n",
    "    obs_diff = np.delete(obs_difff, valid_index)\n",
    "    ts_detail_l = np.concatenate([np.delete(sobol, valid_index, 0)[:ns-32, :8], obs_diff.reshape(-1, 1)], 1)\n",
    "    for i in range(8,9):\n",
    "        minima_det.append(min(ts_detail_l[:,i]))\n",
    "        maxima_det.append(max(ts_detail_l[:,i]))\n",
    "        #ts_detail_l[:,i] = (ts_detail_l[:,i] - np.mean(ts_detail_l[:,i])) / np.std(ts_detail_l[:,i])\n",
    "        ts_detail_l[:,i] = (ts_detail_l[:,i] - min(ts_detail_l[:,i])) / (max(ts_detail_l[:,i])-min(ts_detail_l[:,i]))\n",
    "    training_sets.append(ts_detail_l)\n",
    "\n",
    "#normalize or not the first output\n",
    "#for i in range(8,9):\n",
    "    #training_sets[0][:,i] = (training_sets[0][:,i] - min(training_sets[0][:,i])) / (max(training_sets[0][:,i])-min(training_sets[0][:,i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2528, 9)\n",
      "(608, 9)\n",
      "(128, 9)\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(training_sets[i].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "FIRST 32 ELEMENTS AS VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Random Seed for dataset generation\n",
    "sampling_seed = 74\n",
    "torch.manual_seed(sampling_seed)\n",
    "\n",
    "data101 = np.loadtxt('TrainingData_101.txt', delimiter=' ')\n",
    "data401 = np.loadtxt('TrainingData_401.txt', delimiter=' ')\n",
    "data1601 = np.loadtxt('TrainingData_1601.txt', delimiter=' ')\n",
    "sobol = np.loadtxt('samples_sobol.txt', delimiter=' ')\n",
    "\n",
    "datasets_meshes=[]\n",
    "datasets_meshes.append(data101)\n",
    "datasets_meshes.append(data401)\n",
    "datasets_meshes.append(data1601)\n",
    "\n",
    "training_sets = list()\n",
    "# save min a max of details to detransform the output after NN\n",
    "minima_det = list()\n",
    "maxima_det = list()\n",
    "data_validation = np.concatenate([sobol[:32,:], data1601[:32,8].reshape(-1,1)], 1)\n",
    "ts_detail_l=np.concatenate([sobol[32:,:], data101[32:,8].reshape(-1,1)], 1)\n",
    "training_sets.append(ts_detail_l)\n",
    "\n",
    "# Obtain the details at different mesh resolutions\n",
    "# can try different normalizations for the two details\n",
    "for l in range(1, 3):\n",
    "    ns = datasets_meshes[l].shape[0]\n",
    "    obs_diff = datasets_meshes[l][32:ns, -1] - datasets_meshes[l - 1][32:ns, -1]\n",
    "    ts_detail_l = np.concatenate([sobol[32:ns, :8], obs_diff.reshape(-1, 1)], 1)\n",
    "    for i in range(8,9):\n",
    "        minima_det.append(min(ts_detail_l[:,i]))\n",
    "        maxima_det.append(max(ts_detail_l[:,i]))\n",
    "        #ts_detail_l[:,i] = (ts_detail_l[:,i] - np.mean(ts_detail_l[:,i])) / np.std(ts_detail_l[:,i])\n",
    "        ts_detail_l[:,i] = (ts_detail_l[:,i] - min(ts_detail_l[:,i])) / (max(ts_detail_l[:,i])-min(ts_detail_l[:,i]))\n",
    "    training_sets.append(ts_detail_l)\n",
    "\n",
    "#normalize or not the first output\n",
    "#for i in range(8,9):\n",
    "    #training_sets[0][:,i] = (training_sets[0][:,i] - min(training_sets[0][:,i])) / (max(training_sets[0][:,i])-min(training_sets[0][:,i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5        0.75024438 0.24975562 0.37487781 0.87536657 0.62512219\n",
      " 0.12463343 0.18719453 0.68768328 0.93792766]\n",
      "[0.5    0.75   0.25   0.375  0.875  0.625  0.125  0.1875 0.6875 0.9375]\n"
     ]
    }
   ],
   "source": [
    "#sobol is just the normalization of this\n",
    "data101[:,0] = (data101[:,0] - min(data101[:,0])) / (max(data101[:,0])-min(data101[:,0]))\n",
    "print(data101[:10,0])\n",
    "print(sobol[:10,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "FIRST MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hyperparameters_configurations = {\n",
    "        \"hidden_layers\": [2],\n",
    "        \"neurons\": [25, 30],\n",
    "        \"regularization_exp\": [2],\n",
    "        \"regularization_param\": [0, 1e-4],\n",
    "        \"batch_size\": [2560],\n",
    "        \"epochs\": [2000],\n",
    "        \"optimizer\": [\"LBFGS\"],\n",
    "        \"init_weight_seed\": [567, 1000, 134],\n",
    "        \"activation\": [\"tanh\"]\n",
    "    }\n",
    "\n",
    "settings = list(itertools.product(*hyperparameters_configurations.values()))\n",
    "\n",
    "i = 0\n",
    "\n",
    "train_err_conf = list()\n",
    "val_err_conf = list()\n",
    "for set_num, setup in enumerate(settings):\n",
    "    print(\"###################################\", set_num, \"###################################\")\n",
    "    setup_properties = {\n",
    "        \"hidden_layers\": setup[0],\n",
    "        \"neurons\": setup[1],\n",
    "        \"regularization_exp\": setup[2],\n",
    "        \"regularization_param\": setup[3],\n",
    "        \"batch_size\": setup[4],\n",
    "        \"epochs\": setup[5],\n",
    "        \"optimizer\": setup[6],\n",
    "        \"init_weight_seed\": setup[7],\n",
    "        \"activation\": setup[8]\n",
    "    }\n",
    "\n",
    "    relative_error_train_, relative_error_val_, my_net = run_single_configuration(setup_properties, torch.from_numpy(training_sets[0][:, :8]).type(torch.float32), torch.from_numpy(training_sets[0][:, -1].reshape(-1, 1)).type(torch.float32))\n",
    "    train_err_conf.append(relative_error_train_)\n",
    "    val_err_conf.append(relative_error_val_)\n",
    "\n",
    "train_err_conf = np.array(train_err_conf)\n",
    "val_err_conf = np.array(val_err_conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "SECOND MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hyperparameters_configurations = {\n",
    "        \"hidden_layers\": [2],\n",
    "        \"neurons\": [25, 20],\n",
    "        \"regularization_exp\": [2],\n",
    "        \"regularization_param\": [1e-4, 3e-4],\n",
    "        \"batch_size\": [640],\n",
    "        \"epochs\": [1000],\n",
    "        \"optimizer\": [\"LBFGS\"], ###use LB but then you need to correct the batch size\n",
    "        \"init_weight_seed\": [567, 340],\n",
    "        \"activation\": [\"tanh\"]\n",
    "    }\n",
    "\n",
    "settings = list(itertools.product(*hyperparameters_configurations.values()))\n",
    "\n",
    "i = 0\n",
    "\n",
    "train_err_conf2 = list()\n",
    "val_err_conf2 = list()\n",
    "for set_num, setup in enumerate(settings):\n",
    "    print(\"###################################\", set_num, \"###################################\")\n",
    "    setup_properties = {\n",
    "        \"hidden_layers\": setup[0],\n",
    "        \"neurons\": setup[1],\n",
    "        \"regularization_exp\": setup[2],\n",
    "        \"regularization_param\": setup[3],\n",
    "        \"batch_size\": setup[4],\n",
    "        \"epochs\": setup[5],\n",
    "        \"optimizer\": setup[6],\n",
    "        \"init_weight_seed\": setup[7],\n",
    "        \"activation\": setup[8]\n",
    "    }\n",
    "\n",
    "    relative_error_train_, relative_error_val_, my_net = run_single_configuration(setup_properties, torch.from_numpy(training_sets[1][:, :8]).type(torch.float32), torch.from_numpy(training_sets[1][:, -1].reshape(-1, 1)).type(torch.float32))\n",
    "    train_err_conf2.append(relative_error_train_)\n",
    "    val_err_conf2.append(relative_error_val_)\n",
    "\n",
    "train_err_conf2 = np.array(train_err_conf2)\n",
    "val_err_conf2 = np.array(val_err_conf2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "THIRD MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hyperparameters_configurations = {\n",
    "        \"hidden_layers\": [2],\n",
    "        \"neurons\": [20, 25],\n",
    "        \"regularization_exp\": [0],\n",
    "        \"regularization_param\": [1e-4, 3e-4],\n",
    "        \"batch_size\": [16],\n",
    "        \"epochs\": [1500],\n",
    "        \"optimizer\": [\"ADAM\"], ###use LB but then you need to correct the batch size\n",
    "        \"init_weight_seed\": [567, 34],\n",
    "        \"activation\": [\"tanh\"]\n",
    "    }\n",
    "\n",
    "settings = list(itertools.product(*hyperparameters_configurations.values()))\n",
    "\n",
    "i = 0\n",
    "\n",
    "train_err_conf3 = list()\n",
    "val_err_conf3 = list()\n",
    "for set_num, setup in enumerate(settings):\n",
    "    print(\"###################################\", set_num, \"###################################\")\n",
    "    setup_properties = {\n",
    "        \"hidden_layers\": setup[0],\n",
    "        \"neurons\": setup[1],\n",
    "        \"regularization_exp\": setup[2],\n",
    "        \"regularization_param\": setup[3],\n",
    "        \"batch_size\": setup[4],\n",
    "        \"epochs\": setup[5],\n",
    "        \"optimizer\": setup[6],\n",
    "        \"init_weight_seed\": setup[7],\n",
    "        \"activation\": setup[8]\n",
    "    }\n",
    "\n",
    "    relative_error_train_, relative_error_val_, my_net = run_single_configuration(setup_properties, torch.from_numpy(training_sets[2][:, :8]).type(torch.float32), torch.from_numpy(training_sets[2][:, -1].reshape(-1, 1)).type(torch.float32))\n",
    "    train_err_conf3.append(relative_error_train_)\n",
    "    val_err_conf3.append(relative_error_val_)\n",
    "\n",
    "train_err_conf3 = np.array(train_err_conf3)\n",
    "val_err_conf3 = np.array(val_err_conf3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "CHOOSE THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(np.where(val_err_conf==min(val_err_conf)))\n",
    "print(np.where(val_err_conf2==min(val_err_conf2)))\n",
    "print(np.where(val_err_conf3==min(val_err_conf3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "RUN MODEL 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_layers': 2, 'neurons': 30, 'regularization_exp': 2, 'regularization_param': 0, 'batch_size': 2560, 'epochs': 2000, 'optimizer': 'LBFGS', 'init_weight_seed': 567, 'activation': 'tanh'}\n",
      "Final Training Loss:  2.21e-06\n",
      "Final Validation Loss:  2.47e-06\n",
      "Relative Training Error:  0.3557519055902958 %\n",
      "Relative Validation Error:  0.37645292468369007 %\n"
     ]
    }
   ],
   "source": [
    "approximate_models = list()\n",
    "setup_properties = {\n",
    "        \"hidden_layers\": 2,\n",
    "        \"neurons\": 30,\n",
    "        \"regularization_exp\": 2,\n",
    "        \"regularization_param\": 0,\n",
    "        \"batch_size\": 2560,\n",
    "        \"epochs\": 2000,\n",
    "        \"optimizer\": \"LBFGS\",\n",
    "        \"init_weight_seed\": 567,\n",
    "        \"activation\": \"tanh\"\n",
    "    }\n",
    "\n",
    "relative_error_train_, relative_error_val_, my_network1 = run_single_configuration(setup_properties, torch.from_numpy(training_sets[0][:, :8]).type(torch.float32), torch.from_numpy(training_sets[0][:, -1].reshape(-1, 1)).type(torch.float32))\n",
    "approximate_models.append(my_network1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "RUN MODEL 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \"hidden_layers\": 2,\n",
    "        \"neurons\": 25,\n",
    "        \"regularization_exp\": 2,\n",
    "        \"regularization_param\": 1e-4,\n",
    "        \"batch_size\": 64,\n",
    "        \"epochs\": 1000,\n",
    "        \"optimizer\": \"ADAM\",\n",
    "        \"init_weight_seed\": 567,\n",
    "        \"activation\": \"tanh\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_layers': 0, 'neurons': 25, 'regularization_exp': 2, 'regularization_param': 0.0001, 'batch_size': 64, 'epochs': 2000, 'optimizer': 'ADAM', 'init_weight_seed': 340, 'activation': 'tanh'}\n",
      "Simple linear regression\n",
      "Final Training Loss:  0.01570153\n",
      "Final Validation Loss:  0.01979657\n",
      "Relative Training Error:  28.349989652633667 %\n",
      "Relative Validation Error:  31.646350026130676 %\n"
     ]
    }
   ],
   "source": [
    "setup_properties = {\n",
    "        \"hidden_layers\": 0,\n",
    "        \"neurons\": 25,\n",
    "        \"regularization_exp\": 2,\n",
    "        \"regularization_param\": 1e-4,\n",
    "        \"batch_size\": 64,\n",
    "        \"epochs\": 2000,\n",
    "        \"optimizer\": \"ADAM\",\n",
    "        \"init_weight_seed\": 340,\n",
    "        \"activation\": \"tanh\"\n",
    "    }\n",
    "\n",
    "relative_error_train_, relative_error_val_, my_network2 = run_single_configuration(setup_properties, torch.from_numpy(training_sets[1][:, :8]).type(torch.float32), torch.from_numpy(training_sets[1][:, -1].reshape(-1, 1)).type(torch.float32))\n",
    "approximate_models.append(my_network2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "RUN MODEL 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        \"hidden_layers\": 8,\n",
    "        \"neurons\": 10,\n",
    "        \"regularization_exp\": 0,\n",
    "        \"regularization_param\": 0,\n",
    "        \"batch_size\": 16,\n",
    "        \"epochs\": 1000,\n",
    "        \"optimizer\":  \"ADAM\",\n",
    "        \"init_weight_seed\": 34,\n",
    "        \"activation\": \"relu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_layers': 1, 'neurons': 20, 'regularization_exp': 0, 'regularization_param': 0.0001, 'batch_size': 16, 'epochs': 2000, 'optimizer': 'ADAM', 'init_weight_seed': 567, 'activation': 'tanh'}\n",
      "Final Training Loss:  0.03177037\n",
      "Final Validation Loss:  0.04855589\n",
      "Relative Training Error:  23.816367983818054 %\n",
      "Relative Validation Error:  52.070796489715576 %\n"
     ]
    }
   ],
   "source": [
    "setup_properties = {\n",
    "        \"hidden_layers\": 1,\n",
    "        \"neurons\": 20,\n",
    "        \"regularization_exp\": 0,\n",
    "        \"regularization_param\": 1e-4,\n",
    "        \"batch_size\": 16,\n",
    "        \"epochs\": 2000,\n",
    "        \"optimizer\":  \"ADAM\",\n",
    "        \"init_weight_seed\": 567,\n",
    "        \"activation\": \"tanh\"\n",
    "    }\n",
    "\n",
    "relative_error_train_, relative_error_val_, my_network3 = run_single_configuration(setup_properties, torch.from_numpy(training_sets[2][:, :8]).type(torch.float32), torch.from_numpy(training_sets[2][:, -1].reshape(-1, 1)).type(torch.float32))\n",
    "approximate_models.append(my_network3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "ACCURACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 8])\n",
      "torch.Size([32, 8])\n",
      "Relative Training Error:  0.2739792689681053 %\n",
      "Relative Validation Error:  0.35279830917716026 %\n"
     ]
    }
   ],
   "source": [
    "def predict_with_ml(list_models, inputs_, minima, maxima):\n",
    "    output_ = torch.zeros(inputs_.shape[0], 1)\n",
    "    output_ = output_ + list_models[0](inputs_)\n",
    "    for i in range(1,3):\n",
    "        output_ = output_ + list_models[i](inputs_)*(maxima[i-1]-minima[i-1]) + minima[i-1]\n",
    "    return output_\n",
    "\n",
    "\n",
    "x_predict_train = torch.from_numpy(np.delete(sobol, valid_index, 0)[:128,:8]).type(torch.float32)\n",
    "print(x_predict_train.shape)\n",
    "x_predict_valid = torch.from_numpy(data_validation[:,:8]).type(torch.float32)\n",
    "print(x_predict_valid.shape)\n",
    "y_predict_ml_train = predict_with_ml(approximate_models, x_predict_train ,minima_det, maxima_det).reshape(-1, 1)\n",
    "y_predict_ml_valid = predict_with_ml(approximate_models, x_predict_valid ,minima_det, maxima_det).reshape(-1, 1)\n",
    "\n",
    "real_val_train = torch.from_numpy(np.delete(data1601, valid_index, 0)[:,8]).type(torch.float32).reshape(-1, 1)\n",
    "real_val_valid = torch.from_numpy(data_validation[:,8]).type(torch.float32).reshape(-1, 1)\n",
    "relative_error_train = torch.mean((y_predict_ml_train - real_val_train) ** 2) / torch.mean(real_val_train ** 2)\n",
    "relative_error_valid = torch.mean((y_predict_ml_valid - real_val_valid) ** 2) / torch.mean(real_val_valid ** 2)\n",
    "print(\"Relative Training Error: \", relative_error_train.detach().numpy() ** 0.5 * 100, \"%\")\n",
    "print(\"Relative Validation Error: \", relative_error_valid.detach().numpy() ** 0.5 * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'temp 0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.grid(True, which=\"both\", ls=\":\")\n",
    "plt.scatter(real_val_train.detach(),y_predict_ml_train.detach(), s=20)\n",
    "plt.scatter(real_val_valid.detach(),y_predict_ml_valid.detach(), s=20)\n",
    "#train_pred_ml.detach()\n",
    "plt.xlabel(\"temp\")\n",
    "plt.ylabel(\"temp 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.loadtxt('TestingData.txt', delimiter=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_test = predict_with_ml(approximate_models, torch.from_numpy(test_data).type(torch.float32) ,minima_det, maxima_det).reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLOT THE PREDICTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAVE THE PREDICTIONS IN A TXT FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH=\"Task2\\Submission\"\n",
    "\n",
    "predictions_test=y_predict_test.detach().numpy()\n",
    "\n",
    "np.savetxt(\"angelo_gnazzo_secondo.txt\", predictions_test, fmt='%.18e', delimiter=' ', newline='\\n', header='', footer='', comments='# ', encoding=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "2469a70536e4d2335a2ea8907942d0699c37342a371ac185bdb5b0aa6f073890"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
